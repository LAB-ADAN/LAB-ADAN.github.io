---
title: "Architectural Deep Dive: EFS"
date: 2025-10-30
categories: [AWS Storage]
tags: [EFS, EC2, Storage, NFS]
---

## Architectural Deep Dive: EFS

Amazon Elastic File System (EFS) simplifies how you manage shared storage in AWS.  
It’s scalable, fully managed, and built for high availability across multiple Availability Zones (AZs).

| Feature | The Simple Explanation |
|----------|------------------------|
| **Managed NFS & Multi-AZ** | A file share you never have to manage! It can be mounted on multiple EC2 instances across different AZs, providing built-in redundancy and high availability. |
| **Scalability & Cost** | EFS scales automatically from gigabytes to petabytes with no provisioning required. You pay only for the storage you use. |
| **OS Compatibility** | EFS is designed for Linux-based AMIs. For Windows workloads, you’ll need **FSx for Windows File Server**. |
| **Security First** | Enable encryption at rest with **AWS Key Management Service (KMS)** in just one click. |

---

##  Deep Dive: Performance, Throughput, and Scale

EFS isn’t a one-size-fits-all service — it’s flexible enough to meet a wide range of performance and cost needs. Let’s explore how.

### 1. EFS Scale

EFS is built to handle demanding workloads:

- Supports **thousands of concurrent NFS clients**  
- Provides **up to 10+ GB/s of throughput**  
- Grows automatically to **petabyte scale** — no resizing needed  

### 2. Performance Modes (Latency vs. Throughput)

Choose a performance mode based on your workload needs:

| Mode | Use Case | Description |
|------|-----------|-------------|
| **General Purpose (Default)** | Web servers, CMS, and latency-sensitive apps | Delivers the lowest latency for small, frequent reads/writes. |
| **Max I/O** | Big data analytics, media processing, or highly parallel workloads | Prioritizes throughput and concurrency at the cost of slightly higher latency. |

### 3. Throughput Modes (The Cost/Performance Balancing Act)

This setting defines how EFS delivers performance and scales with cost:

| Mode | How It Works | Best For |
|------|---------------|----------|
| **Elastic (Recommended!)** | Throughput scales automatically with workload demand — up to **3 GB/s for reads**. You pay only for what you use. | Unpredictable workloads such as development or burst traffic. |
| **Bursting** | Throughput scales with your storage size (e.g., **1 TB = 50 MB/s baseline + bursts**). | Predictable workloads with moderate performance needs. |
| **Provisioned** | You define fixed throughput independent of storage size. | Predictable, high-performance workloads with known requirements. |

---

###  The Smart Way to Save: Storage Classes

Since EFS can be more expensive than EBS, AWS offers **storage classes** to help you optimize costs.

| Storage Class | Cost vs. Retrieval | Best For |
|----------------|-------------------|-----------|
| **Standard** | Higher storage cost, no retrieval cost. | Frequently accessed (“hot”) data. |
| **Infrequent Access (EFS-IA)** | Lower storage cost, small retrieval fee. | Files not accessed for 30+ days. |
| **Archive (New)** | Deeply discounted storage, higher retrieval cost. | Rarely accessed, compliance, or historical data. |

> Use Lifecycle Management to automatically move files that haven’t been accessed for, say, 60 days to EFS-IA. Huge savings with zero manual effort!

---
###  Availability: Regional vs. One Zone

Choose availability based on your workload criticality:

| Mode | Description | Best For |
|------|--------------|----------|
| **Regional (Standard)** | Data is replicated across multiple Availability Zones (AZs) for maximum durability and uptime. | Production workloads requiring high availability. |
| **One Zone** | Data is stored in a single AZ for lower cost, with backups enabled by default. | Development, testing, or backup scenarios where lower cost is preferred. |

---

##  Hands-On: Creating a Shared File System

Let’s walk through how to set up **Amazon EFS** to share files between two EC2 instances in different Availability Zones (AZs).

---

###  Step 1: File System Creation

Customize your setup for production readiness:

- **Type:** Regional for multi-AZ availability.  
- **Backups:** Enable automatic backups.  
- **Lifecycle Policies:** Move files to **Infrequent Access (IA)** after 30 days, and back to **Standard** upon first access.  
- **Encryption:** Enable encryption at rest with **AWS KMS**.  
- **Performance:** Use **Elastic Throughput** with **General Purpose** for the best balance of scalability and latency.  

---

###  Step 2: Network Access & Security

Define which instances can mount your EFS:

1. Choose your **VPC** and create a **mount target** in each desired AZ.  
2. Create a dedicated **security group** (e.g., `efs-demo`) for mount targets.  
3. **Important:** Remove the default security group and assign your custom one to all AZs for tighter control.

---

###  Step 3: EC2 Setup and Mounting

1. Launch **two EC2 instances** in different subnets (and therefore, different AZs).  
2. From the **EFS console**, attach the file system to both instances.  

AWS automatically:
- Creates instance-specific security groups (e.g., `efs-sg-1`, `efs-sg-2`).
- Attaches them to the EC2 instances.
- Updates EFS mount target rules to allow **NFS (port 2049)** traffic only between those groups.

---

###  Step 4: Verification

Connect to **Instance A** and create a test file:

```bash
echo "hello world" > /mnt/efs/fs1/hello.txt
cat /mnt/efs/fs1/hello.txt
# Output: hello Rez
```

Then connect to **Instance B**:

```bash
cat /mnt/efs/fs1/hello.txt
# Output: hello Rez
```

